



log.file=log/log.log
##loss.lr.mr.less_memory=true

mode=local

optimization.l2.c=1
optimization.max_iterations=300
test.threshold=0.5

#model.prior.path=src/conf/model
#model.prior.mode=local_text

data.bias=1
data.format=avro

#lbfgs parameter
optimization.lbfgs.m=6
optimization.lbfgs.epsilon=1.5e-5
optimization.liblinear.epsilon=1.5e-3
#owlqn,armijo,wolfe,strong_wolfe
optimization.linesearch=wolfe
optimization.linesearch.max_step=40
optimization.min_step=1e-20
optimization.max_step=1e+20
optimization.ftol=1e-4
optimization.wofle=0.9
optimization.gtol=0.9
#optimization.xtol=0
optimization.l1.c=1
optimization.l1.start=1
optimization.l1.end=124
#optimization.past=2
optimization.delta=1e-5f


#data parameter
#include the bias feature
data.feature.number=124

output.force.overwrite=true

input.paths=./data/a9a.avro
output.path=./result
test.paths=./data/a9a.avro

#hadoop config for all mapreduce
hadoop.mapreduce.job.user.classpath.first=true

#mr1 parameter
#n1.hadoop.mapreduce.job.user.classpath.first=true
lg.hadoop.mapreduce.job.reduces=1
lg.hadoop.mapreduce.input.fileinputformat.split.minsize=1
lg.hadoop.mapreduce.input.fileinputformat.split.maxsize=150000

#mr2 parameter
#n2.hadoop.mapreduce.job.user.classpath.first=true
hv.hadoop.mapreduce.input.fileinputformat.split.maxsize=150000