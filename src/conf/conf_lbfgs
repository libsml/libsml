##loss=lr
##num=3
progress.file=process
##loss.lr.mr.less_memory=true

mode=local

#default 0
optimization.l2.c=1
optimization.max_iterations=300
test.threshold=0.5

#w.path

data.bias=1
data.format=avro

#lbfgs parameter
optimization.lbfgs.m=6
optimization.lbfgs.epsilon=1.5e-5
optimization.liblinear.epsilon=1.5e-3
#owlqn,armijo,wolfe,strong_wolfe
optimization.linesearch=wolfe
optimization.linesearch.max_step=40
optimization.min_step=1e-20
optimization.max_step=1e+20
optimization.ftol=1e-4
optimization.wofle=0.9
optimization.gtol=0.9
#optimization.xtol=0
optimization.l1.c=1
optimization.l1.start=1
optimization.l1.end=124
#optimization.past=2
optimization.delta=1e-5f


#data parameter
#include the bias feature
data.feature.number=125

output.force.overwrite=true
#input.paths=hy/lbfgs/data/train
#output.path=hy/lbfgs/out
#test.path=hy/lbfgs/data/test

input.paths=./data/a9a.avro
output.path=./result
test.paths=./data/a9a.avro

#hadoop config for all mapreduce
hadoop.mapreduce.job.user.classpath.first=true

#mr1 parameter
#n1.hadoop.mapreduce.job.user.classpath.first=true
n1.hadoop.mapreduce.job.reduces=1
n1.hadoop.mapreduce.input.fileinputformat.split.minsize=1
n1.hadoop.mapreduce.input.fileinputformat.split.maxsize=150000
n1.hadoop.mapreduce.job.name=lbfgs_test_mr1

#mr2 parameter
#n2.hadoop.mapreduce.job.user.classpath.first=true